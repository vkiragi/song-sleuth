(function (global, factory) {
    typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports, require('@babel/runtime/helpers/defineProperty'), require('@babel/runtime/helpers/asyncToGenerator'), require('@babel/runtime/helpers/typeof'), require('@babel/runtime/regenerator'), require('fast-unique-numbers'), require('standardized-audio-context')) :
    typeof define === 'function' && define.amd ? define(['exports', '@babel/runtime/helpers/defineProperty', '@babel/runtime/helpers/asyncToGenerator', '@babel/runtime/helpers/typeof', '@babel/runtime/regenerator', 'fast-unique-numbers', 'standardized-audio-context'], factory) :
    (global = typeof globalThis !== 'undefined' ? globalThis : global || self, factory(global.webAudioBeatDetectorBroker = {}, global._defineProperty, global._asyncToGenerator, global._typeof, global._regeneratorRuntime, global.fastUniqueNumbers, global.standardizedAudioContext));
})(this, (function (exports, _defineProperty, _asyncToGenerator, _typeof, _regeneratorRuntime, fastUniqueNumbers, standardizedAudioContext) { 'use strict';

    var render = function render(audioBuffer, offset, duration) {
      var offlineAudioContext = new standardizedAudioContext.OfflineAudioContext(audioBuffer.numberOfChannels, Math.round(duration * audioBuffer.sampleRate), audioBuffer.sampleRate);
      var biquadFilter = offlineAudioContext.createBiquadFilter();
      var bufferSourceNode = offlineAudioContext.createBufferSource();
      biquadFilter.frequency.value = 240;
      biquadFilter.type = 'lowpass';
      bufferSourceNode.buffer = audioBuffer;
      bufferSourceNode.connect(biquadFilter).connect(offlineAudioContext.destination);
      bufferSourceNode.start(0, offset, duration);
      return offlineAudioContext.startRendering().then(function (renderedBuffer) {
        var channelData = renderedBuffer.getChannelData(0);
        var sampleRate = renderedBuffer.sampleRate;
        return {
          channelData: channelData,
          sampleRate: sampleRate
        };
      });
    };

    function ownKeys(e, r) { var t = Object.keys(e); if (Object.getOwnPropertySymbols) { var o = Object.getOwnPropertySymbols(e); r && (o = o.filter(function (r) { return Object.getOwnPropertyDescriptor(e, r).enumerable; })), t.push.apply(t, o); } return t; }
    function _objectSpread(e) { for (var r = 1; r < arguments.length; r++) { var t = null != arguments[r] ? arguments[r] : {}; r % 2 ? ownKeys(Object(t), !0).forEach(function (r) { _defineProperty(e, r, t[r]); }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(e, Object.getOwnPropertyDescriptors(t)) : ownKeys(Object(t)).forEach(function (r) { Object.defineProperty(e, r, Object.getOwnPropertyDescriptor(t, r)); }); } return e; }
    var load = function load(url) {
      var worker = new Worker(url);
      var ongoingRecordingRequests = new Set();
      var analyze = function analyze() {
        var _a;
        for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {
          args[_key] = arguments[_key];
        }
        var audioBuffer = args[0],
          offsetOrTempoSettings = args[1],
          durationOrTempoSettings = args[2];
        var offset = typeof offsetOrTempoSettings === 'number' ? offsetOrTempoSettings : 0;
        var duration = typeof durationOrTempoSettings === 'number' ? durationOrTempoSettings : audioBuffer.duration - offset;
        var tempoSettings = _typeof(offsetOrTempoSettings) === 'object' ? offsetOrTempoSettings : _typeof(durationOrTempoSettings) === 'object' ? durationOrTempoSettings : (_a = args[3]) !== null && _a !== void 0 ? _a : null;
        return new Promise( /*#__PURE__*/function () {
          var _ref = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(resolve, reject) {
            var _yield$render, channelData, sampleRate, id, onMessage;
            return _regeneratorRuntime.wrap(function _callee$(_context) {
              while (1) switch (_context.prev = _context.next) {
                case 0:
                  _context.next = 2;
                  return render(audioBuffer, offset, duration);
                case 2:
                  _yield$render = _context.sent;
                  channelData = _yield$render.channelData;
                  sampleRate = _yield$render.sampleRate;
                  id = fastUniqueNumbers.addUniqueNumber(ongoingRecordingRequests);
                  onMessage = function onMessage(_ref2) {
                    var data = _ref2.data;
                    if (data.id === id) {
                      ongoingRecordingRequests["delete"](id);
                      worker.removeEventListener('message', onMessage);
                      if (data.error === null) {
                        resolve(data.result.tempo);
                      } else {
                        reject(new Error(data.error.message));
                      }
                    }
                  };
                  worker.addEventListener('message', onMessage);
                  worker.postMessage({
                    id: id,
                    method: 'analyze',
                    params: _objectSpread({
                      channelData: channelData,
                      sampleRate: sampleRate
                    }, tempoSettings === null ? tempoSettings : {
                      tempoSettings: tempoSettings
                    })
                  }, [channelData.buffer]);
                case 9:
                case "end":
                  return _context.stop();
              }
            }, _callee);
          }));
          return function (_x, _x2) {
            return _ref.apply(this, arguments);
          };
        }());
      };
      var guess = function guess() {
        var _a;
        for (var _len2 = arguments.length, args = new Array(_len2), _key2 = 0; _key2 < _len2; _key2++) {
          args[_key2] = arguments[_key2];
        }
        var audioBuffer = args[0],
          offsetOrTempoSettings = args[1],
          durationOrTempoSettings = args[2];
        var offset = typeof offsetOrTempoSettings === 'number' ? offsetOrTempoSettings : 0;
        var duration = typeof durationOrTempoSettings === 'number' ? durationOrTempoSettings : audioBuffer.duration - offset;
        var tempoSettings = _typeof(offsetOrTempoSettings) === 'object' ? offsetOrTempoSettings : _typeof(durationOrTempoSettings) === 'object' ? durationOrTempoSettings : (_a = args[3]) !== null && _a !== void 0 ? _a : null;
        return new Promise( /*#__PURE__*/function () {
          var _ref3 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(resolve, reject) {
            var _yield$render2, channelData, sampleRate, id, onMessage;
            return _regeneratorRuntime.wrap(function _callee2$(_context2) {
              while (1) switch (_context2.prev = _context2.next) {
                case 0:
                  _context2.next = 2;
                  return render(audioBuffer, offset, duration);
                case 2:
                  _yield$render2 = _context2.sent;
                  channelData = _yield$render2.channelData;
                  sampleRate = _yield$render2.sampleRate;
                  id = fastUniqueNumbers.addUniqueNumber(ongoingRecordingRequests);
                  onMessage = function onMessage(_ref4) {
                    var data = _ref4.data;
                    if (data.id === id) {
                      ongoingRecordingRequests["delete"](id);
                      worker.removeEventListener('message', onMessage);
                      if (data.error === null) {
                        resolve(data.result);
                      } else {
                        reject(new Error(data.error.message));
                      }
                    }
                  };
                  worker.addEventListener('message', onMessage);
                  worker.postMessage({
                    id: id,
                    method: 'guess',
                    params: _objectSpread({
                      channelData: channelData,
                      sampleRate: sampleRate
                    }, tempoSettings === null ? tempoSettings : {
                      tempoSettings: tempoSettings
                    })
                  }, [channelData.buffer]);
                case 9:
                case "end":
                  return _context2.stop();
              }
            }, _callee2);
          }));
          return function (_x3, _x4) {
            return _ref3.apply(this, arguments);
          };
        }());
      };
      return {
        analyze: analyze,
        guess: guess
      };
    };

    Object.defineProperty(exports, "isSupported", {
        enumerable: true,
        get: function () { return standardizedAudioContext.isSupported; }
    });
    exports.load = load;

}));
